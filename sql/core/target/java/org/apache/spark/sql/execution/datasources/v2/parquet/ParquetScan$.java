package org.apache.spark.sql.execution.datasources.v2.parquet;
public  class ParquetScan$ extends scala.runtime.AbstractFunction11<org.apache.spark.sql.SparkSession, org.apache.hadoop.conf.Configuration, org.apache.spark.sql.execution.datasources.PartitioningAwareFileIndex, org.apache.spark.sql.types.StructType, org.apache.spark.sql.types.StructType, org.apache.spark.sql.types.StructType, org.apache.spark.sql.sources.Filter[], org.apache.spark.sql.util.CaseInsensitiveStringMap, scala.Option<org.apache.spark.sql.connector.expressions.aggregate.Aggregation>, scala.collection.Seq<org.apache.spark.sql.catalyst.expressions.Expression>, scala.collection.Seq<org.apache.spark.sql.catalyst.expressions.Expression>, org.apache.spark.sql.execution.datasources.v2.parquet.ParquetScan> implements scala.Serializable {
  /**
   * Static reference to the singleton instance of this Scala object.
   */
  public static final ParquetScan$ MODULE$ = null;
  public   ParquetScan$ ()  { throw new RuntimeException(); }
}
