package org.apache.spark.status.api.v1;
public  class ApplicationEnvironmentInfo {
  // not preceding
     ApplicationEnvironmentInfo (org.apache.spark.status.api.v1.RuntimeInfo runtime, scala.collection.Seq<scala.Tuple2<java.lang.String, java.lang.String>> sparkProperties, scala.collection.Seq<scala.Tuple2<java.lang.String, java.lang.String>> hadoopProperties, scala.collection.Seq<scala.Tuple2<java.lang.String, java.lang.String>> systemProperties, scala.collection.Seq<scala.Tuple2<java.lang.String, java.lang.String>> classpathEntries, scala.collection.Seq<org.apache.spark.status.api.v1.ResourceProfileInfo> resourceProfiles)  { throw new RuntimeException(); }
  public  scala.collection.Seq<scala.Tuple2<java.lang.String, java.lang.String>> classpathEntries ()  { throw new RuntimeException(); }
  public  scala.collection.Seq<scala.Tuple2<java.lang.String, java.lang.String>> hadoopProperties ()  { throw new RuntimeException(); }
  public  scala.collection.Seq<org.apache.spark.status.api.v1.ResourceProfileInfo> resourceProfiles ()  { throw new RuntimeException(); }
  public  org.apache.spark.status.api.v1.RuntimeInfo runtime ()  { throw new RuntimeException(); }
  public  scala.collection.Seq<scala.Tuple2<java.lang.String, java.lang.String>> sparkProperties ()  { throw new RuntimeException(); }
  public  scala.collection.Seq<scala.Tuple2<java.lang.String, java.lang.String>> systemProperties ()  { throw new RuntimeException(); }
}
