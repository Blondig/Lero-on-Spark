package org.apache.spark.status.api.v1;
public  class TaskMetricDistributions {
  // not preceding
     TaskMetricDistributions (scala.collection.IndexedSeq<java.lang.Object> quantiles, scala.collection.IndexedSeq<java.lang.Object> duration, scala.collection.IndexedSeq<java.lang.Object> executorDeserializeTime, scala.collection.IndexedSeq<java.lang.Object> executorDeserializeCpuTime, scala.collection.IndexedSeq<java.lang.Object> executorRunTime, scala.collection.IndexedSeq<java.lang.Object> executorCpuTime, scala.collection.IndexedSeq<java.lang.Object> resultSize, scala.collection.IndexedSeq<java.lang.Object> jvmGcTime, scala.collection.IndexedSeq<java.lang.Object> resultSerializationTime, scala.collection.IndexedSeq<java.lang.Object> gettingResultTime, scala.collection.IndexedSeq<java.lang.Object> schedulerDelay, scala.collection.IndexedSeq<java.lang.Object> peakExecutionMemory, scala.collection.IndexedSeq<java.lang.Object> memoryBytesSpilled, scala.collection.IndexedSeq<java.lang.Object> diskBytesSpilled, org.apache.spark.status.api.v1.InputMetricDistributions inputMetrics, org.apache.spark.status.api.v1.OutputMetricDistributions outputMetrics, org.apache.spark.status.api.v1.ShuffleReadMetricDistributions shuffleReadMetrics, org.apache.spark.status.api.v1.ShuffleWriteMetricDistributions shuffleWriteMetrics)  { throw new RuntimeException(); }
  public  scala.collection.IndexedSeq<java.lang.Object> diskBytesSpilled ()  { throw new RuntimeException(); }
  public  scala.collection.IndexedSeq<java.lang.Object> duration ()  { throw new RuntimeException(); }
  public  scala.collection.IndexedSeq<java.lang.Object> executorCpuTime ()  { throw new RuntimeException(); }
  public  scala.collection.IndexedSeq<java.lang.Object> executorDeserializeCpuTime ()  { throw new RuntimeException(); }
  public  scala.collection.IndexedSeq<java.lang.Object> executorDeserializeTime ()  { throw new RuntimeException(); }
  public  scala.collection.IndexedSeq<java.lang.Object> executorRunTime ()  { throw new RuntimeException(); }
  public  scala.collection.IndexedSeq<java.lang.Object> gettingResultTime ()  { throw new RuntimeException(); }
  public  org.apache.spark.status.api.v1.InputMetricDistributions inputMetrics ()  { throw new RuntimeException(); }
  public  scala.collection.IndexedSeq<java.lang.Object> jvmGcTime ()  { throw new RuntimeException(); }
  public  scala.collection.IndexedSeq<java.lang.Object> memoryBytesSpilled ()  { throw new RuntimeException(); }
  public  org.apache.spark.status.api.v1.OutputMetricDistributions outputMetrics ()  { throw new RuntimeException(); }
  public  scala.collection.IndexedSeq<java.lang.Object> peakExecutionMemory ()  { throw new RuntimeException(); }
  public  scala.collection.IndexedSeq<java.lang.Object> quantiles ()  { throw new RuntimeException(); }
  public  scala.collection.IndexedSeq<java.lang.Object> resultSerializationTime ()  { throw new RuntimeException(); }
  public  scala.collection.IndexedSeq<java.lang.Object> resultSize ()  { throw new RuntimeException(); }
  public  scala.collection.IndexedSeq<java.lang.Object> schedulerDelay ()  { throw new RuntimeException(); }
  public  org.apache.spark.status.api.v1.ShuffleReadMetricDistributions shuffleReadMetrics ()  { throw new RuntimeException(); }
  public  org.apache.spark.status.api.v1.ShuffleWriteMetricDistributions shuffleWriteMetrics ()  { throw new RuntimeException(); }
}
