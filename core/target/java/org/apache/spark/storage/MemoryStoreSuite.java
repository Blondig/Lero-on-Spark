package org.apache.spark.storage;
public  class MemoryStoreSuite extends org.apache.spark.SparkFunSuite implements org.scalatest.PrivateMethodTester, org.scalatest.BeforeAndAfterEach, org.apache.spark.util.ResetSystemProperties {
  public   MemoryStoreSuite ()  { throw new RuntimeException(); }
  public  org.scalatest.PrivateMethodTester.PrivateMethod$ PrivateMethod ()  { throw new RuntimeException(); }
  public  org.apache.spark.storage.BlockId StringToBlockId (java.lang.String value)  { throw new RuntimeException(); }
  public  void afterEach ()  { throw new RuntimeException(); }
  public  void beforeEach ()  { throw new RuntimeException(); }
  public  org.apache.spark.SparkConf conf ()  { throw new RuntimeException(); }
  public  scala.Tuple2<org.apache.spark.storage.memory.MemoryStore, org.apache.spark.storage.BlockInfoManager> makeMemoryStore (long maxMem)  { throw new RuntimeException(); }
  public  java.util.Properties oldProperties ()  { throw new RuntimeException(); }
  public  java.lang.String originalArch ()  { throw new RuntimeException(); }
  public  java.lang.String originalCompressedOops ()  { throw new RuntimeException(); }
  public  org.apache.spark.storage.RDDBlockId rdd (int rddId, int splitId)  { throw new RuntimeException(); }
  public  void reinitializeSizeEstimator (java.lang.String arch, java.lang.String useCompressedOops)  { throw new RuntimeException(); }
  public  org.apache.spark.serializer.KryoSerializer serializer ()  { throw new RuntimeException(); }
  public  org.apache.spark.serializer.SerializerManager serializerManager ()  { throw new RuntimeException(); }
  public <T extends java.lang.Object> void testPutIteratorAsValues (scala.Function0<T> smallListValue, scala.Function0<T> bigListValue, org.apache.spark.storage.StorageLevel storageLevel)  { throw new RuntimeException(); }
}
